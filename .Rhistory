values_from = c(median_time, mean_bias)
) %>%
mutate(
speed_ratio     = round(median_time_none / median_time_none, 2),     # always 1
bias_reduction  = round(
100 * (mean_bias_none - mean_bias_0.05) / mean_bias_none, 1)
) %>%
select(n, k, speed_ratio, bias_reduction)
############################################################
##  Summarise FLEXIC vs IC results   (nine n × k cells)
############################################################
# 1.  Packages ------------------------------------------------------
if (!requireNamespace("dplyr", quietly = TRUE)) install.packages("dplyr")
if (!requireNamespace("tidyr", quietly = TRUE)) install.packages("tidyr")
library(dplyr); library(tidyr)
# 2.  Load the CSV you just created --------------------------------
df <- read.csv("E:/06_NNCORx/flexic_ic_sim_results2.csv",
stringsAsFactors = FALSE)
# 3.  Ensure eps is character --------------------------------------
df$eps <- as.character(df$eps)          # "none" or "0.05"
# 4.  Collapse to nine n × k cells ---------------------------------
summary_tbl <- df %>%
group_by(n, k, eps) %>%                     # average over ρ
summarise(
median_time = median(time_ms, na.rm = TRUE),
mean_bias   = mean(abs_rel_bias, na.rm = TRUE),
.groups = "drop"
) %>%
tidyr::pivot_wider(
names_from  = eps,
values_from = c(median_time, mean_bias)
) %>%                             # now have *_none and *_0.05 columns
mutate(
bias_reduction = round(
100 * (mean_bias_none - mean_bias_0.05) / mean_bias_none, 1)
) %>%
dplyr::select(n, k,
median_time_none,
bias_reduction) %>%
arrange(n, k)
# 5.  Print the nine-cell table ------------------------------------
print(summary_tbl, n = Inf)
############################################################
##  Recreate the full summary table   (n × k × rho × eps)
##  exactly like yesterday, but from the new CSV
############################################################
# 1.  Load your raw replication file -------------------------------
df <- read.csv("E:/06_NNCORx/flexic_ic_results.csv",
stringsAsFactors = FALSE)
############################################################
##  Recreate the full summary table   (n × k × rho × eps)
##  exactly like yesterday, but from the new CSV
############################################################
# 1.  Load your raw replication file -------------------------------
df <- read.csv("E:/06_NNCORx/flexic_ic_results2.csv",
stringsAsFactors = FALSE)
# 1.  Load your raw replication file -------------------------------
df <- read.csv("E:/06_NNCORx/flexic_sim_results2.csv",
stringsAsFactors = FALSE)
# 1.  Load your raw replication file -------------------------------
df <- read.csv("E:/06_NNCORx/flexic_ic_sim_results2.csv",
stringsAsFactors = FALSE)
# 2.  Median run-time for each cell --------------------------------
med_time <- aggregate(time_ms ~ n + k + rho + eps,
data = df, FUN = median)
# 3.  Mean absolute relative bias for each cell --------------------
mean_bias <- aggregate(abs_rel_bias ~ n + k + rho + eps,
data = df, FUN = mean)
# 4.  Merge the two summaries -------------------------------------
table_full <- merge(med_time, mean_bias,
by = c("n", "k", "rho", "eps"))
# 5.  Order rows the same as yesterday (n ascending, then k, rho) --
table_full <- table_full[order(table_full$n,
table_full$k,
table_full$rho,
table_full$eps), ]
# 6.  Rename columns to match old printout -------------------------
names(table_full)[names(table_full) == "time_ms"]      <- "median_time_ms"
names(table_full)[names(table_full) == "abs_rel_bias"] <- "mean_abs_rel_bias"
# 7.  Inspect in console ------------------------------------------
print(head(table_full, 12))
# ------------------------------------------------------------
# Empirical vignette with plots: true_ic vs FLEXIC
# ------------------------------------------------------------
if (!requireNamespace("MASS", quietly = TRUE)) install.packages("MASS")
library(MASS)
## -- Helper functions ---------------------------------------
true_ic <- function(data, Sigma) {
n <- nrow(data); k <- ncol(data)
Z <- mvrnorm(n, rep(0, k), Sigma)
ranks <- apply(Z, 2, rank, ties.method = "random")
out   <- matrix(NA_real_, n, k)
for (j in 1:k)
out[order(ranks[, j]), j] <- sort(data[, j])
out
}
flex_ic <- function(data, Sigma, eps = "none", max_try = 20) {
n <- nrow(data); k <- ncol(data)
if (eps == "none") {
Z <- mvrnorm(n, rep(0, k), Sigma)          # accept first draw
} else {
target_S <- (6 / pi) * asin(Sigma[1, 2] / 2)
repeat {
Z <- mvrnorm(n, rep(0, k), Sigma)
if (abs(cor(Z, method = "spearman")[1,2] - target_S) < eps) break
}
}
ranks <- apply(Z, 2, rank, ties.method = "random")
out   <- matrix(NA_real_, n, k)
for (j in 1:k)
out[order(ranks[, j]), j] <- sort(data[, j])
out
}
## -- Prepare skewed data ------------------------------------
dat <- na.omit(airquality[, c("Ozone", "Solar.R")])
set.seed(0514)
dat_u <- apply(dat, 2, sample)                 # scramble columns
## -- Target Spearman ρ = .60 --------------------------------
rho <- 0.60
Sigma <- matrix(rho, 2, 2); diag(Sigma) <- 1
run_one <- function(label, FUN) {
tic <- Sys.time()
out <- FUN()
c(Method       = label,
Time_ms      = round(1000 * difftime(Sys.time(), tic, units = "secs"), 2),
Achieved_rho = round(cor(out, method = "spearman")[1,2], 3))
}
res <- rbind(
run_one("true_ic (classic)",         function() true_ic(dat_u, Sigma)),
run_one("FLEXIC  eps=\"none\"",      function() flex_ic(dat_u, Sigma, "none")),
run_one("FLEXIC  eps=0.03",          function() flex_ic(dat_u, Sigma, eps=0.03))
)
res <- as.data.frame(res)
res$Raw_Bias <- round(abs(as.numeric(res$Achieved_rho) - rho), 3)
print(res, row.names = FALSE)
## -- Plot marginals (original vs FLEXIC tight) ---------------
png("E:/06_NNCORx/ozone_hist_compare.png", 720, 340)
par(mfrow = c(1,2), mar = c(4,4,3,1))
hist(dat_u[,1],      col = "skyblue", breaks = 20,
main = "Ozone (original)", xlab = "")
hist(flex_ic(dat_u, Sigma, 0.03)[,1], col = "tan", breaks = 20,
main = "Ozone (after FLEXIC ε=0.03)", xlab = "")
dev.off()
cat("Histogram saved to 'ozone_hist_compare.png'\n")
# ===========================================================
# Crossed Benchmark: IC vs FLEXIC (Flexible IC) with Bias Mean and Variance
# ===========================================================
if (!requireNamespace("MASS", quietly = TRUE)) install.packages("MASS")
library(MASS)
# ---------- 1. Helper Functions ----------
# Generate weird marginals
generate_weird_marginals <- function(n, k) {
marginals <- matrix(NA, nrow = n, ncol = k)
for (i in 1:k) {
dist_type <- sample(c("chisq", "exp", "beta", "binom"), 1)
if (dist_type == "chisq") {
marginals[, i] <- rchisq(n, df = 3)
} else if (dist_type == "exp") {
marginals[, i] <- rexp(n, rate = 1)
} else if (dist_type == "beta") {
marginals[, i] <- rbeta(n, shape1 = 2, shape2 = 5)
} else if (dist_type == "binom") {
marginals[, i] <- rbinom(n, size = 5, prob = 0.4)
}
}
marginals
}
# True Iman–Conover reordering
true_ic <- function(data, Sigma) {
n <- nrow(data)
k <- ncol(data)
Z <- mvrnorm(n, rep(0, k), Sigma)
ranks_Z <- apply(Z, 2, rank, ties.method = "random")
X_new <- matrix(NA_real_, n, k)
for (j in 1:k) {
X_new[order(ranks_Z[, j]), j] <- sort(data[, j])
}
X_new
}
# FLEXIC method (fastIC flexible mode)
flex_ic <- function(data, Sigma, eps = 0.05, max_try = 20) {
n <- nrow(data)
k <- ncol(data)
if (eps == "none") {
# No checking — just accept first MVN draw
Z <- mvrnorm(n, rep(0, k), Sigma)
ranks_Z <- apply(Z, 2, rank, ties.method = "random")
X_new <- matrix(NA_real_, n, k)
for (j in 1:k) {
X_new[order(ranks_Z[, j]), j] <- sort(data[, j])
}
return(X_new)
}
target_S <- (6 / pi) * asin(Sigma[1, 2] / 2)
tries <- 0
repeat {
tries <- tries + 1
Z <- mvrnorm(n, rep(0, k), Sigma)
sample_S <- cor(Z, method = "spearman")[upper.tri(Sigma)]
err <- max(abs(sample_S - target_S))
if (err < eps || tries >= max_try) {
ranks_Z <- apply(Z, 2, rank, ties.method = "random")
X_new <- matrix(NA_real_, n, k)
for (j in 1:k) {
X_new[order(ranks_Z[, j]), j] <- sort(data[, j])
}
return(X_new)
}
}
}
# ---------- 2. Benchmarking Function ----------
full_crossed_benchmark_bias <- function(n_values, k_values, rho = 0.65, reps = 10, eps = 0.05) {
results <- list()
for (n in n_values) {
for (k in k_values) {
Sigma <- matrix(rho, k, k)
diag(Sigma) <- 1
ic_times <- numeric(reps)
flexic_times <- numeric(reps)
ic_biases <- numeric(reps)
flexic_biases <- numeric(reps)
for (i in 1:reps) {
set.seed(i + n + k)
weird_data <- generate_weird_marginals(n, k)
# IC
start_ic <- Sys.time()
ic_data <- true_ic(weird_data, Sigma)
end_ic <- Sys.time()
ic_times[i] <- as.numeric(difftime(end_ic, start_ic, units = "secs"))
# Calculate IC bias
ic_spearman <- cor(ic_data, method = "spearman")[upper.tri(Sigma)]
target_S <- (6 / pi) * asin(Sigma[1, 2] / 2)
ic_rel_bias <- (ic_spearman - target_S) / target_S
ic_biases[i] <- mean(abs(ic_rel_bias))
# FLEXIC
start_flexic <- Sys.time()
flexic_data <- flex_ic(weird_data, Sigma, eps = eps)
end_flexic <- Sys.time()
flexic_times[i] <- as.numeric(difftime(end_flexic, start_flexic, units = "secs"))
# Calculate FLEXIC bias
flexic_spearman <- cor(flexic_data, method = "spearman")[upper.tri(Sigma)]
flexic_rel_bias <- (flexic_spearman - target_S) / target_S
flexic_biases[i] <- mean(abs(flexic_rel_bias))
}
median_ic <- median(ic_times)
median_flexic <- median(flexic_times)
mean_ic <- mean(ic_times)
mean_flexic <- mean(flexic_times)
speedup_median <- median_ic / median_flexic
speedup_mean <- mean_ic / mean_flexic
mean_abs_bias_ic <- mean(ic_biases)
mean_abs_bias_flexic <- mean(flexic_biases)
var_abs_bias_ic <- var(ic_biases)
var_abs_bias_flexic <- var(flexic_biases)
results[[paste0("n", n, "_k", k)]] <- data.frame(
n = n,
k = k,
median_time_IC_sec = median_ic,
median_time_flexIC_sec = median_flexic,
speedup_median = round(speedup_median, 2),
mean_time_IC_sec = mean_ic,
mean_time_flexIC_sec = mean_flexic,
speedup_mean = round(speedup_mean, 2),
mean_abs_rel_bias_IC = mean_abs_bias_ic,
mean_abs_rel_bias_flexIC = mean_abs_bias_flexic,
var_abs_rel_bias_IC = var_abs_bias_ic,
var_abs_rel_bias_flexIC = var_abs_bias_flexic
)
}
}
do.call(rbind, results)
}
# ---------- 3. Run It ----------
# Define grid
n_values <- c(200, 500, 1000)
k_values <- c(2, 5, 10)
# Run full crossed simulation
benchmark_crossed_results_with_bias <- full_crossed_benchmark_bias(n_values, k_values, rho = 0.65, reps = 1000, eps = 0.05)
# ===========================================================
# Crossed Benchmark: IC vs FLEXIC (Flexible IC), Varying n, k, rho
# ===========================================================
if (!requireNamespace("MASS", quietly = TRUE)) install.packages("MASS")
library(MASS)
# ---------- 1. Helper Functions ----------
# Generate weird marginals
generate_weird_marginals <- function(n, k) {
marginals <- matrix(NA, nrow = n, ncol = k)
for (i in 1:k) {
dist_type <- sample(c("chisq", "exp", "beta", "binom"), 1)
if (dist_type == "chisq") {
marginals[, i] <- rchisq(n, df = 3)
} else if (dist_type == "exp") {
marginals[, i] <- rexp(n, rate = 1)
} else if (dist_type == "beta") {
marginals[, i] <- rbeta(n, shape1 = 2, shape2 = 5)
} else if (dist_type == "binom") {
marginals[, i] <- rbinom(n, size = 5, prob = 0.4)
}
}
marginals
}
# True IC
true_ic <- function(data, Sigma) {
n <- nrow(data)
k <- ncol(data)
Z <- mvrnorm(n, rep(0, k), Sigma)
ranks_Z <- apply(Z, 2, rank, ties.method = "random")
X_new <- matrix(NA_real_, n, k)
for (j in 1:k) {
X_new[order(ranks_Z[, j]), j] <- sort(data[, j])
}
return(X_new)
}
# FLEXIC
flex_ic <- function(data, Sigma, eps = 0.05, max_try = 20) {
n <- nrow(data)
k <- ncol(data)
if (eps == "none") {
Z <- mvrnorm(n, rep(0, k), Sigma)
ranks_Z <- apply(Z, 2, rank, ties.method = "random")
X_new <- matrix(NA_real_, n, k)
for (j in 1:k) {
X_new[order(ranks_Z[, j]), j] <- sort(data[, j])
}
return(X_new)
}
target_S <- (6 / pi) * asin(Sigma[1, 2] / 2)
tries <- 0
repeat {
tries <- tries + 1
Z <- mvrnorm(n, rep(0, k), Sigma)
sample_S <- cor(Z, method = "spearman")[upper.tri(Sigma)]
err <- max(abs(sample_S - target_S))
if (err < eps || tries >= max_try) {
ranks_Z <- apply(Z, 2, rank, ties.method = "random")
X_new <- matrix(NA_real_, n, k)
for (j in 1:k) {
X_new[order(ranks_Z[, j]), j] <- sort(data[, j])
}
return(X_new)
}
}
}
# ---------- 2. Benchmarking Function ----------
full_crossed_benchmark_bias_rho <- function(n_values, k_values, rho_conditions, reps = 10, eps = 0.05) {
results <- list()
for (n in n_values) {
for (k in k_values) {
for (rho_label in names(rho_conditions)) {
rho_val <- rho_conditions[[rho_label]]
Sigma <- matrix(rho_val, k, k)
diag(Sigma) <- 1
ic_times <- numeric(reps)
flexic_times <- numeric(reps)
ic_biases <- numeric(reps)
flexic_biases <- numeric(reps)
for (i in 1:reps) {
set.seed(i + n + k)
weird_data <- generate_weird_marginals(n, k)
# IC
start_ic <- Sys.time()
ic_data <- true_ic(weird_data, Sigma)
end_ic <- Sys.time()
ic_times[i] <- as.numeric(difftime(end_ic, start_ic, units = "secs"))
# Calculate IC bias
ic_spearman <- cor(ic_data, method = "spearman")[upper.tri(Sigma)]
target_S <- (6 / pi) * asin(Sigma[1, 2] / 2)
ic_rel_bias <- (ic_spearman - target_S) / target_S
ic_biases[i] <- mean(abs(ic_rel_bias))
# FLEXIC
start_flexic <- Sys.time()
flexic_data <- flex_ic(weird_data, Sigma, eps = eps)
end_flexic <- Sys.time()
flexic_times[i] <- as.numeric(difftime(end_flexic, start_flexic, units = "secs"))
# Calculate FLEXIC bias
flexic_spearman <- cor(flexic_data, method = "spearman")[upper.tri(Sigma)]
flexic_rel_bias <- (flexic_spearman - target_S) / target_S
flexic_biases[i] <- mean(abs(flexic_rel_bias))
}
median_ic <- median(ic_times)
median_flexic <- median(flexic_times)
mean_ic <- mean(ic_times)
mean_flexic <- mean(flexic_times)
speedup_median <- median_ic / median_flexic
speedup_mean <- mean_ic / mean_flexic
mean_abs_bias_ic <- mean(ic_biases)
mean_abs_bias_flexic <- mean(flexic_biases)
var_abs_bias_ic <- var(ic_biases)
var_abs_bias_flexic <- var(flexic_biases)
results[[paste0("n", n, "_k", k, "_rho", rho_label)]] <- data.frame(
n = n,
k = k,
rho_label = rho_label,
rho_value = rho_val,
median_time_IC_sec = median_ic,
median_time_flexIC_sec = median_flexic,
speedup_median = round(speedup_median, 2),
mean_time_IC_sec = mean_ic,
mean_time_flexIC_sec = mean_flexic,
speedup_mean = round(speedup_mean, 2),
mean_abs_rel_bias_IC = mean_abs_bias_ic,
mean_abs_rel_bias_flexIC = mean_abs_bias_flexic,
var_abs_rel_bias_IC = var_abs_bias_ic,
var_abs_rel_bias_flexIC = var_abs_bias_flexic
)
}
}
}
do.call(rbind, results)
}
# ---------- 3. Run It ----------
# Define grids
n_values <- c(200, 500, 1000)
k_values <- c(2, 5, 10)
rho_conditions <- list(low = 0.3, medium = 0.65, high = 0.9)
# Run full crossed simulation
benchmark_crossed_results_with_rho <- full_crossed_benchmark_bias_rho(n_values, k_values, rho_conditions, reps = 10, eps = "none")
# View results
print(benchmark_crossed_results_with_rho)
# ===============================================================
# fastIC_eps_benchmark.R
# IC  : deterministic Iman–Conover permutation
# Stoch: single-draw accept-until-ε (MVN draw + ε check)
# Grid: n × k × eps   •   500 reps per cell
# ===============================================================
library(MASS)           # mvrnorm()
library(microbenchmark)
## --- 1.  Algorithms ---------------------------------------------
ic_exact <- function(n, Sigma) {
k  <- ncol(Sigma)
Z  <- mvrnorm(n, rep(0, k), Sigma)
R  <- apply(Z, 2, rank, ties.method = "first")
Zs <- apply(Z, 2, sort)
X  <- matrix(NA_real_, n, k)
for (j in seq_len(k)) X[R[, j], j] <- Zs[, j]
X
}
stochIC <- function(n, Sigma, eps = 0.04, max_try = 20) {
target_S <- (6 / pi) * asin(Sigma[1, 2] / 2)
tries <- 0
repeat {
tries <- tries + 1
Z   <- mvrnorm(n, rep(0, ncol(Sigma)), Sigma)
err <- max(abs(cor(Z, method = "spearman")[upper.tri(Sigma)] - target_S))
if (err < eps || tries >= max_try) {
attr(Z, "tries") <- tries
attr(Z, "err")   <- err
return(Z)
}
}
}
## --- 2.  Design grid --------------------------------------------
n_vec   <- c(200, 500, 1000, 5000)
k_vec   <- c(2, 5, 10)
eps_vec <- c(0.02, 0.04, 0.06)
rho     <- 0.65
reps    <- 1000
grid <- expand.grid(n = n_vec, k = k_vec, eps = eps_vec,
KEEP.OUT.ATTRS = FALSE)
set.seed(42)            # reproducible redraw counts
run_cell <- function(n, k, eps) {
Sigma <- matrix(rho, k, k); diag(Sigma) <- 1
mb <- microbenchmark(
IC    = ic_exact(n, Sigma),
Stoch = stochIC(n, Sigma, eps = eps),
times = reps, unit = "ms"
)
med_ic    <- median(mb$time[mb$expr == "IC"])    / 1e6
med_st    <- median(mb$time[mb$expr == "Stoch"]) / 1e6
speed_up  <- round(med_ic / med_st, 2)
last <- stochIC(n, Sigma, eps = eps)
data.frame(
n, k, eps,
med_ms_IC    = round(med_ic,    2),
med_ms_Stoch = round(med_st,    2),
speed_up,
redraws      = attr(last, "tries"),
max_delta    = round(attr(last, "err"), 4)
)
}
results <- do.call(
rbind,
Map(run_cell, grid$n, grid$k, grid$eps)
)
write.csv(results, "E:/06_NNCORx/fastIC_eps_benchx.csv", row.names = FALSE)
print(results)
## (optional) save raw timing objects
# saveRDS(results, "fastIC_eps_raw.rds")
res <- read.table("clipboard", header = TRUE)  # or df <- your data frame
head(clipboard)
res <- read.table("clipboard", header = TRUE)  # or df <- your data frame
# pick IC baseline as eps = max (0.06)
library(dplyr)
res <- res %>%
group_by(n, k) %>%
mutate(bias_cut = round(100 * (first(max_delta) - max_delta) / first(max_delta), 0)) %>%
ungroup()
pubtab <- res %>%
mutate(
IC_ms    = round(med_ms_IC, 2),
FLEX_ms  = round(med_ms_Stoch, 2),
speed    = round(speed_up, 2),
maxDelta = sprintf("%.4f", max_delta),
BiasCut  = paste0("↓", bias_cut, "%")
) %>%
select(n, k, eps, IC_ms, FLEX_ms, speed, redraws, maxDelta, BiasCut)
print(pubtab, row.names = FALSE)
print(pubtab, row.names = FALSE, n=36)
getwd()
setwd("D:/flexIC_0.1.2")
devtools::document()
devtools::check()
